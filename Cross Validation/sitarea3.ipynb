{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Logistic Regression","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(../input/02-titanic/02-titanic.csv)\ndf.drop('Ticket', axis=1, inplace=True)\ndf.drop('Name', axis=1, inplace=True)\ndf.drop('Cabin', axis=1, inplace=True)\nX = df.drop(['Survived'], axis=1).values\ny = df['Survived']\ndf['Age'] = df['Age'].astype(float).fillna(df['Age'].mean()).astype(int)\nfrom sklearn.model_selection import train_test_split \nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\nfrom sklearn.linear_model import LogisticRegression\nl_g = LogisticRegression(max_iter = 800)\nfrom sklearn.model_selection import KFold \nfrom sklearn.base import clone  \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport statistics\n    \n    kf = KFold(n_splits=10,shuffle=True, random_state=42) \n    acs_folds = []\n    ps_folds = []\n    rs_folds = []\n    f_folds = []\n    for train_index, test_index in kf.split(X):\n        cloned_clf = clone(model) #clona el clasificador\n        \n      \n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index] \n        cloned_clf.fit(X_train, y_train)  \n        y_pred = cloned_clf.predict(X_test) \n        acs = accuracy_score(y_test,y_pred) \n        ps = precision_score(y_test,y_pred)\n        rs = recall_score(y_test,y_pred)\n        f1 = f1_score(y_test,y_pred)\n        \n        acs_folds.append(acs)  \n        ps_folds.append(ps)\n        rs_folds.append(rs)\n        f_folds.append(f1)\n        \n        print('accuracy:', acs,'precision:',ps,'recall:',rs, 'f-score', f1)\n    \n    print('\\nMean accuracy:', sum(acs_folds)/len(acs_folds))\n    print('Standard deviation:',statistics.stdev(acs_folds,))\n    \n    model.fit(X_train, y_train)\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\ncross_validation(l_g, X_train,X_test,y_train,y_test,X,y)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Desicion Tree","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(../input/02-titanic/02-titanic.csv)\ndf.drop('Ticket', axis=1, inplace=True)\ndf.drop('Name', axis=1, inplace=True)\ndf.drop('Cabin', axis=1, inplace=True)\nX = df.drop(['Survived'], axis=1).values\ny = df['Survived']\ndf['Age'] = df['Age'].astype(float).fillna(df['Age'].mean()).astype(int)\nfrom sklearn.model_selection import train_test_split \nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\nfrom sklearn.tree import DesicionTreeClassifier\ntree= DesicionTreeClassifier()\nfrom sklearn.model_selection import KFold \nfrom sklearn.base import clone  \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport statistics\n    \n    kf = KFold(n_splits=10,shuffle=True, random_state=42) \n    acs_folds = []\n    ps_folds = []\n    rs_folds = []\n    f_folds = []\n    for train_index, test_index in kf.split(X):\n        cloned_clf = clone(model) #clona el clasificador\n        \n      \n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index] \n        cloned_clf.fit(X_train, y_train)  \n        y_pred = cloned_clf.predict(X_test) \n        acs = accuracy_score(y_test,y_pred) \n        ps = precision_score(y_test,y_pred)\n        rs = recall_score(y_test,y_pred)\n        f1 = f1_score(y_test,y_pred)\n        \n        acs_folds.append(acs)  \n        ps_folds.append(ps)\n        rs_folds.append(rs)\n        f_folds.append(f1)\n        \n        print('accuracy:', acs,'precision:',ps,'recall:',rs, 'f-score', f1)\n    \n    print('\\nMean accuracy:', sum(acs_folds)/len(acs_folds))\n    print('Standard deviation:',statistics.stdev(acs_folds,))\n    \n    model.fit(X_train, y_train)\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\ncross_validation(tree, X_train,X_test,y_train,y_test,X,y)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Rbf","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(../input/02-titanic/02-titanic.csv)\ndf.drop('Ticket', axis=1, inplace=True)\ndf.drop('Name', axis=1, inplace=True)\ndf.drop('Cabin', axis=1, inplace=True)\nX = df.drop(['Survived'], axis=1).values\ny = df['Survived']\ndf['Age'] = df['Age'].astype(float).fillna(df['Age'].mean()).astype(int)\nfrom sklearn.model_selection import train_test_split \nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\nfrom sklearn.svm import SVC\nrbf= SVC(kernel='rbf')\nfrom sklearn.model_selection import KFold \nfrom sklearn.base import clone  \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport statistics\n    \n    kf = KFold(n_splits=10,shuffle=True, random_state=42) \n    acs_folds = []\n    ps_folds = []\n    rs_folds = []\n    f_folds = []\n    for train_index, test_index in kf.split(X):\n        cloned_clf = clone(model) #clona el clasificador\n        \n      \n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index] \n        cloned_clf.fit(X_train, y_train)  \n        y_pred = cloned_clf.predict(X_test) \n        acs = accuracy_score(y_test,y_pred) \n        ps = precision_score(y_test,y_pred)\n        rs = recall_score(y_test,y_pred)\n        f1 = f1_score(y_test,y_pred)\n        \n        acs_folds.append(acs)  \n        ps_folds.append(ps)\n        rs_folds.append(rs)\n        f_folds.append(f1)\n        \n        print('accuracy:', acs,'precision:',ps,'recall:',rs, 'f-score', f1)\n    \n    print('\\nMean accuracy:', sum(acs_folds)/len(acs_folds))\n    print('Standard deviation:',statistics.stdev(acs_folds,))\n    \n    model.fit(X_train, y_train)\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\ncross_validation(rbf, X_train,X_test,y_train,y_test,X,y)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Linear","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(../input/02-titanic/02-titanic.csv)\ndf.drop('Ticket', axis=1, inplace=True)\ndf.drop('Name', axis=1, inplace=True)\ndf.drop('Cabin', axis=1, inplace=True)\nX = df.drop(['Survived'], axis=1).values\ny = df['Survived']\ndf['Age'] = df['Age'].astype(float).fillna(df['Age'].mean()).astype(int)\nfrom sklearn.model_selection import train_test_split \nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\nfrom sklearn.svm import SVC\nlinear= SVC(kernel='linear')\nfrom sklearn.model_selection import KFold \nfrom sklearn.base import clone  \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport statistics\n    \n    kf = KFold(n_splits=10,shuffle=True, random_state=42) \n    acs_folds = []\n    ps_folds = []\n    rs_folds = []\n    f_folds = []\n    for train_index, test_index in kf.split(X):\n        cloned_clf = clone(model) #clona el clasificador\n        \n      \n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index] \n        cloned_clf.fit(X_train, y_train)  \n        y_pred = cloned_clf.predict(X_test) \n        acs = accuracy_score(y_test,y_pred) \n        ps = precision_score(y_test,y_pred)\n        rs = recall_score(y_test,y_pred)\n        f1 = f1_score(y_test,y_pred)\n        \n        acs_folds.append(acs)  \n        ps_folds.append(ps)\n        rs_folds.append(rs)\n        f_folds.append(f1)\n        \n        print('accuracy:', acs,'precision:',ps,'recall:',rs, 'f-score', f1)\n    \n    print('\\nMean accuracy:', sum(acs_folds)/len(acs_folds))\n    print('Standard deviation:',statistics.stdev(acs_folds,))\n    \n    model.fit(X_train, y_train)\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\ncross_validation(linear, X_train,X_test,y_train,y_test,X,y)","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Neural Network","metadata":{}},{"cell_type":"code","source":"import numpy as np\nimport pandas as pd\ndf = pd.read_csv(../input/02-titanic/02-titanic.csv)\ndf.drop('Ticket', axis=1, inplace=True)\ndf.drop('Name', axis=1, inplace=True)\ndf.drop('Cabin', axis=1, inplace=True)\nX = df.drop(['Survived'], axis=1).values\ny = df['Survived']\ndf['Age'] = df['Age'].astype(float).fillna(df['Age'].mean()).astype(int)\nfrom sklearn.model_selection import train_test_split \nX_train, X_test , y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=27)\nfrom sklearn.neural_network import MLPClassifier\nn_n= MLPClassifier (hidden_layer_sizes=(10,10,10,10), max_iter=100)\nfrom sklearn.model_selection import KFold \nfrom sklearn.base import clone  \nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nimport statistics\n    \n    kf = KFold(n_splits=10,shuffle=True, random_state=42) \n    acs_folds = []\n    ps_folds = []\n    rs_folds = []\n    f_folds = []\n    for train_index, test_index in kf.split(X):\n        cloned_clf = clone(model) #clona el clasificador\n        \n      \n        X_train, X_test = X[train_index], X[test_index] \n        y_train, y_test = y[train_index], y[test_index] \n        cloned_clf.fit(X_train, y_train)  \n        y_pred = cloned_clf.predict(X_test) \n        acs = accuracy_score(y_test,y_pred) \n        ps = precision_score(y_test,y_pred)\n        rs = recall_score(y_test,y_pred)\n        f1 = f1_score(y_test,y_pred)\n        \n        acs_folds.append(acs)  \n        ps_folds.append(ps)\n        rs_folds.append(rs)\n        f_folds.append(f1)\n        \n        print('accuracy:', acs,'precision:',ps,'recall:',rs, 'f-score', f1)\n    \n    print('\\nMean accuracy:', sum(acs_folds)/len(acs_folds))\n    print('Standard deviation:',statistics.stdev(acs_folds,))\n    \n    model.fit(X_train, y_train)\n    RocCurveDisplay.from_estimator(model, X_test, y_test)\ncross_validation(n_n, X_train,X_test,y_train,y_test,X,y)\n","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Tuve problemas para correrlos, ya que me aparecia un error en el archivo, que no era válido. Por lo que no pude corroborar cual era mejor","metadata":{}}]}